# m3_searcher.py (ë°˜í™˜ í˜•íƒœ ìˆ˜ì •)
import streamlit as st
import requests

def search_news_articles(claims: list[str]) -> dict[str, list[str]]:
    """
    í•µì‹¬ ì£¼ì¥ì„ ë°›ì•„ ë„¤ì´ë²„ ê²€ìƒ‰ APIë¡œ 'ì£¼ì¥: URL ë¦¬ìŠ¤íŠ¸' ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    client_id = st.secrets.get("NAVER_CLIENT_ID")
    client_secret = st.secrets.get("NAVER_CLIENT_SECRET")

    if not client_id or not client_secret:
        st.error("ğŸ”‘ ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .streamlit/secrets.toml íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return {}

    url = "https://openapi.naver.com/v1/search/news.json"
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret,
    }
    
    # [ìˆ˜ì •] ê²°ê³¼ë¥¼ ë‹´ì„ ìë£Œêµ¬ì¡°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€ê²½
    search_results = {}

    for query in claims:
        params = {"query": query, "display": 5, "sort": "sim"}
        
        try:
            response = requests.get(url, headers=headers, params=params)
            response.raise_for_status()
            data = response.json()
            
            # [ìˆ˜ì •] í˜„ì¬ ì¿¼ë¦¬ì— ëŒ€í•œ URLë§Œ ì¶”ì¶œ
            urls_for_query = []
            for item in data.get("items", []):
                if "news.naver.com" in item.get("link", ""):
                    urls_for_query.append(item["link"])
            
            # [ìˆ˜ì •] ì¿¼ë¦¬ë¥¼ keyë¡œ, URL ë¦¬ìŠ¤íŠ¸ë¥¼ valueë¡œ ì €ì¥
            if urls_for_query: # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ ì¶”ê°€
                search_results[query] = urls_for_query

        except requests.exceptions.RequestException as e:
            st.error(f"'{query}' ê²€ìƒ‰ ì¤‘ API ì˜¤ë¥˜: {e}")
            continue

    return search_results